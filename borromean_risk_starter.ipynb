{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc7e027",
   "metadata": {},
   "source": [
    "\n",
    "# Borromean Risk Starter Notebook\n",
    "\n",
    "This notebook is a runnable scaffold to experiment with a Borromean-ring risk model for mass movements (landslides, rockfalls, debris/mudflows, lava flows).  \n",
    "You’ll find:\n",
    "\n",
    "- Data model placeholders\n",
    "- Functions to compute **H** (Event Drivers), **L** (Local Lore & History), **V** (Vulnerability)\n",
    "- Borromean **noisy-AND** + synergy scoring\n",
    "- A toy synthetic example you can replace with real data\n",
    "\n",
    "> Replace the **TODO** cells with your region-specific data ingest and features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ddea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Minimal dependencies for the starter. Expand as needed (rasterio, geopandas, shapely, etc.).\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "np.random.seed(7)\n",
    "print(\"Environment ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439d5b4a",
   "metadata": {},
   "source": [
    "\n",
    "## Configuration\n",
    "\n",
    "Adjust these parameters as needed for your pilot region and hazard type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONFIG = {\n",
    "    \"hazard_type\": \"landslide\",  # 'landslide' | 'rockfall' | 'debris_flow' | 'lava_flow'\n",
    "    \"grid_shape\": (80, 80),      # rows, cols for the toy raster\n",
    "    \"resolution_m\": 10,\n",
    "    \"time_window\": \"2024-07\",    # label for the scoring window\n",
    "    # Borromean thresholds/weights (initial defaults; calibrate later)\n",
    "    \"tau_H\": 0.35,\n",
    "    \"tau_L\": 0.25,\n",
    "    \"tau_V\": 0.30,\n",
    "    \"lambda_mix\": 0.7,\n",
    "    \"kappa_synergy\": 0.3,\n",
    "    \"alpha\": 1.0, \"beta\": 1.0, \"gamma\": 1.0,\n",
    "}\n",
    "CONFIG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c8793",
   "metadata": {},
   "source": [
    "\n",
    "## Toy data (synthetic)\n",
    "\n",
    "This creates synthetic rasters for slope, lithology class, rainfall exceedance, lore density, exposure, and fragility.  \n",
    "Swap this out with real data ingestion in the next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows, cols = CONFIG[\"grid_shape\"]\n",
    "# Synthetic terrain proxy\n",
    "slope_deg = np.clip(np.random.normal(loc=25, scale=10, size=(rows, cols)), 0, 60)\n",
    "curvature = np.clip(np.random.normal(loc=0, scale=0.5, size=(rows, cols)), -2, 2)\n",
    "\n",
    "# Synthetic dynamic trigger: rainfall I-D exceedance flag (0..1 probability proxy)\n",
    "rain_exceed = np.clip(np.random.beta(a=2, b=5, size=(rows, cols)), 0, 1)\n",
    "\n",
    "# Synthetic 'lithology erodibility' class mapped to 0..1\n",
    "lith_classes = np.random.randint(1, 6, size=(rows, cols))  # 1 (hardest) .. 5 (weakest)\n",
    "lith_erod = (lith_classes - 1) / 4.0\n",
    "\n",
    "# Toy lore features: per-cell aggregated score stubs (0..1)\n",
    "lore_signal = np.clip(np.random.beta(a=1.5, b=3.5, size=(rows, cols)), 0, 1)\n",
    "\n",
    "# Vulnerability: exposure (0..1) and fragility (0..1)\n",
    "exposure = np.clip(np.random.beta(a=2.5, b=2.5, size=(rows, cols)), 0, 1)\n",
    "fragility = np.clip(np.random.beta(a=2.0, b=3.0, size=(rows, cols)), 0, 1)\n",
    "\n",
    "print(\"Toy rasters synthesized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c29c33",
   "metadata": {},
   "source": [
    "\n",
    "## TODO: Real data ingestion\n",
    "\n",
    "Replace the synthetic section by reading your real rasters/vectors (DEM-derived slope/curvature, lithology, rainfall or ShakeMap, event inventories, asset layers).\n",
    "\n",
    "**Hints:**\n",
    "- Use `rasterio.open(...).read(1)` for rasters, and reprojection to a common CRS/resolution.\n",
    "- Use `geopandas.read_file(...)` for vectors, rasterize as needed to the working grid.\n",
    "- Cache intermediate arrays with `np.save`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2816ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example structure (commented out; edit for your environment)\n",
    "# import rasterio\n",
    "# import geopandas as gpd\n",
    "# from rasterio.features import rasterize\n",
    "#\n",
    "# with rasterio.open(\"slope.tif\") as src:\n",
    "#     slope_deg = src.read(1).astype(float)\n",
    "#\n",
    "# gdf_assets = gpd.read_file(\"assets.gpkg\")\n",
    "# ... rasterize exposure/criticality ...\n",
    "#\n",
    "# lore_df = pd.read_parquet(\"lore_features.parquet\")  # pre-aggregated per cell & window\n",
    "# lore_signal = lore_df.pivot_table(index=\"row\", columns=\"col\", values=\"L\").values\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac89124",
   "metadata": {},
   "source": [
    "\n",
    "## Feature transforms: **H**, **L**, **V**\n",
    "\n",
    "This section converts raw ingredients into normalized 0..1 scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic(x, k=1.0, x0=0.0):\n",
    "    return 1.0 / (1.0 + np.exp(-k * (x - x0)))\n",
    "\n",
    "def compute_H(slope_deg, curvature, lith_erod, rain_exceed, hazard_type=\"landslide\"):\n",
    "    # Example blend; tune per hazard type.\n",
    "    slope_term = logistic(slope_deg, k=0.15, x0=20)          # more risk with steeper slopes\n",
    "    curv_term  = logistic(-curvature, k=0.8, x0=0)           # concave (negative) raises risk\n",
    "    lith_term  = lith_erod                                   # already [0,1]\n",
    "    rain_term  = rain_exceed                                 # trigger proxy\n",
    "    \n",
    "    # Simple weighted mean then clamp 0..1\n",
    "    w = np.array([0.4, 0.15, 0.15, 0.3])\n",
    "    H = np.clip(w[0]*slope_term + w[1]*curv_term + w[2]*lith_term + w[3]*rain_term, 0, 1)\n",
    "    return H\n",
    "\n",
    "def compute_L(lore_signal):\n",
    "    # Assume lore_signal ∈ [0,1] already (from fuzzy pipeline aggregation)\n",
    "    return np.clip(lore_signal, 0, 1)\n",
    "\n",
    "def compute_V(exposure, fragility, criticality_weight=0.3):\n",
    "    # Combine exposure and fragility; optionally add criticality later\n",
    "    V = np.clip(0.7*exposure + 0.3*fragility, 0, 1)\n",
    "    return V\n",
    "\n",
    "H = compute_H(slope_deg, curvature, lith_erod, rain_exceed, CONFIG[\"hazard_type\"])\n",
    "L = compute_L(lore_signal)\n",
    "V = compute_V(exposure, fragility)\n",
    "\n",
    "H.min(), H.max(), L.min(), L.max(), V.min(), V.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7070315",
   "metadata": {},
   "source": [
    "\n",
    "## Borromean scoring\n",
    "\n",
    "Implements product **noisy-AND** plus a synergy term based on the **min(H,L,V)** limiter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def borromean_score(H, L, V, params):\n",
    "    tau_H, tau_L, tau_V = params[\"tau_H\"], params[\"tau_L\"], params[\"tau_V\"]\n",
    "    alpha, beta, gamma = params[\"alpha\"], params[\"beta\"], params[\"gamma\"]\n",
    "    lam, kappa = params[\"lambda_mix\"], params[\"kappa_synergy\"]\n",
    "\n",
    "    # Threshold gate: require all rings above their tau_* (boolean mask)\n",
    "    gate = (H > tau_H) & (L > tau_L) & (V > tau_V)\n",
    "\n",
    "    # Product t-norm (noisy-AND style)\n",
    "    R0 = (H**alpha) * (L**beta) * (V**gamma)\n",
    "\n",
    "    # Synergy: weakest ring limits the triad\n",
    "    S = kappa * np.minimum(np.minimum(H, L), V)\n",
    "\n",
    "    R = lam * R0 + (1 - lam) * S\n",
    "    R = np.where(gate, R, 0.0)\n",
    "    return np.clip(R, 0, 1), gate\n",
    "\n",
    "R, gate = borromean_score(H, L, V, CONFIG)\n",
    "float(R.mean()), gate.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5babfa09",
   "metadata": {},
   "source": [
    "\n",
    "## Uncertainty (toy example)\n",
    "\n",
    "A tiny Monte Carlo that injects small noise into H/L/V to produce an approximate \\(\\sigma_R\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ee61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mc_uncertainty(H, L, V, params, n=60, sigma=0.05):\n",
    "    samples = []\n",
    "    for _ in range(n):\n",
    "        Hs = np.clip(H + np.random.normal(0, sigma, H.shape), 0, 1)\n",
    "        Ls = np.clip(L + np.random.normal(0, sigma, L.shape), 0, 1)\n",
    "        Vs = np.clip(V + np.random.normal(0, sigma, V.shape), 0, 1)\n",
    "        Rs, _ = borromean_score(Hs, Ls, Vs, params)\n",
    "        samples.append(Rs)\n",
    "    stack = np.stack(samples, axis=0)\n",
    "    return stack.mean(axis=0), stack.std(axis=0)\n",
    "\n",
    "R_mean, R_std = mc_uncertainty(H, L, V, CONFIG, n=60, sigma=0.04)\n",
    "float(R_std.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158577e",
   "metadata": {},
   "source": [
    "\n",
    "## Quick-look visualization\n",
    "\n",
    "Three ring heatmaps and the final risk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# H\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"H: Event Driver\")\n",
    "plt.imshow(H, origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# L\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"L: Local Lore & History\")\n",
    "plt.imshow(L, origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# V\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"V: Vulnerability\")\n",
    "plt.imshow(V, origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Risk\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"R: Borromean Risk (mean)\")\n",
    "plt.imshow(R_mean, origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dc0e53",
   "metadata": {},
   "source": [
    "\n",
    "## Export results (flat table)\n",
    "\n",
    "Creates a CSV with H, L, V, R, and uncertainty for the toy grid. Replace with GeoTIFF/COG in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b43f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows, cols = H.shape\n",
    "df = pd.DataFrame({\n",
    "    \"row\": np.repeat(np.arange(rows), cols),\n",
    "    \"col\": np.tile(np.arange(cols), rows),\n",
    "    \"H\": H.flatten(),\n",
    "    \"L\": L.flatten(),\n",
    "    \"V\": V.flatten(),\n",
    "    \"R_mean\": R_mean.flatten(),\n",
    "    \"R_std\": R_std.flatten(),\n",
    "    \"gate\": gate.flatten().astype(int),\n",
    "    \"hazard_type\": CONFIG[\"hazard_type\"],\n",
    "    \"time_window\": CONFIG[\"time_window\"]\n",
    "})\n",
    "out_path = \"/mnt/data/borromean_risk_toy_results.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "out_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ec3dc",
   "metadata": {},
   "source": [
    "\n",
    "## Save config & params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/mnt/data/borromean_config.json\", \"w\") as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\"/mnt/data/borromean_config.json\"\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
